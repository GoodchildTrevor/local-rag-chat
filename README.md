# Offline RAG Pipeline with Qdrant and llama.cpp

This project implements a lightweight **Retrieval-Augmented Generation (RAG)** pipeline using **FastAPI**, **Qdrant**, and a local **llama.cpp** model. It runs fully offline â€” ideal for self-hosted or air-gapped environments.

## âœ¨ Features

- ğŸ“„ Local document ingestion with metadata support
- âš¡ OCR support for scanned documents via Tesseract
- ğŸ” Hybrid search (semantic + full-text) powered by **Qdrant**
- ğŸ§  Context-aware answers from local **llama.cpp** model
- ğŸ–¼ï¸ Web UI via **[NiceGUI](https://nicegui.io/)**

## ğŸ“¦ Required Tools

### Docker
[Installation guide](https://docs.docker.com/engine/install/)

### Qdrant
[Installation guide](https://qdrant.tech/documentation/guides/installation/)

### Ollama
[Installation guide](https://apxml.com/courses/getting-started-local-llms/chapter-4-running-first-local-llm/setting-up-ollama)

### Tesseract
[Installation guide](https://builtin.com/articles/python-tesseract)

## ğŸš€ Getting Started
Create a `.env` file in the root directory:

```
HOST=                     # your host
APP_PORT =                # port for FastAPI
DB_PORT=                  # port for Qdrant
REDIS_PORT=               # port for Redis
RAG_DOC_COLLECTION=       # name of your main collection
CASH_COLLECTION=          # name of cashing answer collection
SESSION_TIMEOUT_MINUTES=  # length of session
```

```bash
# 1. Run docker images
docker compose pull
docker compose up -d
# 2. Install dependencies
pip install -r requirements.txt
# 3. Create your document collection
python database/collection_creator/collection_creator.py
# 4. Upsert your documents
python database//document_upserting/etl.py
# 5. Run the API server
python main.py
# 6. Open the GUI
# http://localhost:{APP_PORT}
```

## ğŸ“‚ Project Structure
```
RAG/
â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ interface/            # NiceGUI frontend and utilities
â”‚   â””â”€â”€ backend/              # Dialogue logic
â”œâ”€â”€ config/                   # All constants for all components
â”œâ”€â”€ consts/                   # All main constants
â”œâ”€â”€ database/                 # Database scripts
â”‚   â”œâ”€â”€ cashing/              # Cashing of the best llm answers
â”‚   â”œâ”€â”€ collection_creator/   # Create/recreate collection
â”‚   â”œâ”€â”€ document_upserting/   # Upsert documents
â”‚   â”œâ”€â”€ documents/            # Raw documents to be indexed
â”‚   â””â”€â”€ searcher/             # Seacrh engine
â”œâ”€â”€ llm/                      # Ollama config and inference scripts
â””â”€â”€ main.py                   # Entry point
```
